{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c2ce46-786c-4413-b762-33b5f00df34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d720ff7e-fc49-4537-9e32-ee29987576d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/ReportsDATASET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f41ac53-50d4-4c86-9a57-ef50b7e3104d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXAM(S): Chest, 2 views, frontal and lateral\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nExam\\nXray Chest PA and Lateral\\n\\nDate\\nXXX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>\\nExam\\nPA and lateral views of the chest, XXX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExam\\nPA and lateral che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>\\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nHisto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nEXAM\\nPA and lateral vie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1984 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text\n",
       "0     \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...\n",
       "1     EXAM(S): Chest, 2 views, frontal and lateral\\n...\n",
       "2     \\nExam\\nXray Chest PA and Lateral\\n\\nDate\\nXXX...\n",
       "3     \\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...\n",
       "4     \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...\n",
       "...                                                 ...\n",
       "1979  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...\n",
       "1980  \\nExam\\nPA and lateral views of the chest, XXX...\n",
       "1981  \\nRADIOLOGY REPORT\\n\\nExam\\nPA and lateral che...\n",
       "1982  \\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nHisto...\n",
       "1983  \\nRADIOLOGY REPORT\\n\\nEXAM\\nPA and lateral vie...\n",
       "\n",
       "[1984 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad68df1d-c6cb-49e3-89fd-2257e4fad602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest PA and Lateral\\nExam: 2 views of the chest XXXX/XXXX.\\n \\nComparison: None.\\n \\nIndication: Positive TB test\\n \\nFindings:\\nThe cardiac silhouette and mediastinum size are within normal limits.\\nThere is no pulmonary edema. There is no focal consolidation. There\\nare no XXXX of a pleural effusion. There is no evidence of\\npneumothorax.\\n \\nImpression:\\nNormal chest x-XXXX. \\nThis examination and reported findings have been reviewed and\\nconfirmed by the undersigned.\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de743e7f-b18e-44ab-8c4e-d6d9b5748969",
   "metadata": {},
   "source": [
    "## Run llama 3 locally\n",
    "\n",
    "- install `ollama`\n",
    "- run `ollama pull llama3` to pull down the llama 3 8B model \n",
    "- start the model running using `ollama run llama3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e51dcb6-8346-471d-9a5b-02abc26e2c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b121a070-9d32-4ac0-b957-261ceadfc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:11434/api/chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54f8cf18-804a-4ecb-b3f5-669cf3158619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama3(prompt: str) -> str:\n",
    "    data = {\n",
    "        \"model\": \"llama3\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "    return response.json()['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e51af8-456a-4b77-a0cd-2a46a41bfb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llama3(\"who wrote the book the godfather?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d4f297-b911-469a-bdbb-21a17147e9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The book \"The Godfather\" was written by Mario Puzo, an American author and screenwriter. The novel was published in 1969 and tells the story of the Corleone crime family, which is based on the Italian-American Mafia.\\n\\nPuzo\\'s novel was a huge success, and it went on to be adapted into a film of the same name by Francis Ford Coppola in 1972. The movie starred Marlon Brando as Don Vito Corleone and became one of the most iconic and influential films in cinema history.\\n\\nMario Puzo wrote several other novels and screenplays throughout his career, but \"The Godfather\" remains his most famous work.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28517819-f505-40bf-9fb8-24cd3cf2a48d",
   "metadata": {},
   "source": [
    "### Extract labels using llama 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1c933ec-5b2b-4d7f-afbe-86525fe1a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f0856a2-778c-417e-a691-53d53764f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of abnormalities\n",
    "abnormalities = [\"pulmonary edema\", \"consolidation\", \"pleural effusion\", \"pneumothorax\", \"cardiomegaly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe5675f4-2c43-47c2-bc28-f342cc340a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_abnormalities(report):\n",
    "    global abnormalities\n",
    "    \n",
    "    # Initialize results\n",
    "    results = {abnormality: 0 for abnormality in abnormalities}\n",
    "    \n",
    "    # Prepare the prompt for the GPT-4 model\n",
    "    prompt = f\"Read the following radiology report and identify the presence or absence of the following abnormalities: {', '.join(abnormalities)}.\\n\\nReport:\\n{report}\\n\\nOutput the results, formatted in xml, with each of the abnormalities with 0 for absence and 1 for presence. The output should be xml with no other text.\"\n",
    "    \n",
    "    # Get the classification results from llama 3\n",
    "    response = llama3(prompt)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e463097-c832-4a81-9e73-91da413ed978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_xml_string(xml_string):\n",
    "    \"\"\"\n",
    "    Clean the XML string to ensure it is well-formed.\n",
    "    \"\"\"\n",
    "    # Remove leading/trailing whitespace\n",
    "    xml_string = xml_string.strip()\n",
    "    \n",
    "    # Normalize the XML string\n",
    "    xml_string = xml_string.replace('-', '_').lower()\n",
    "    xml_string = xml_string.replace('pulmonary edema', 'pulmonary_edema').lower()\n",
    "    xml_string = xml_string.replace('pulmonaryedema', 'pulmonary_edema').lower()\n",
    "    xml_string = xml_string.replace('pleural effusion', 'pleural_effusion').lower()\n",
    "    xml_string = xml_string.replace('pleuraleffusion', 'pleural_effusion').lower()\n",
    "    \n",
    "    # Additional cleaning steps can be added here if needed\n",
    "    \n",
    "    return xml_string\n",
    "\n",
    "def extract_abnormalities_from_xml(xml_string):\n",
    "    \"\"\"\n",
    "    This function extracts abnormalities and their values from the given XML string.\n",
    "    \"\"\"\n",
    "    # Clean the XML string\n",
    "    xml_string = clean_xml_string(xml_string)\n",
    "    \n",
    "    # Define the list of abnormalities we're interested in\n",
    "    abnormalities = [\"pulmonary_edema\", \"consolidation\", \"pleural_effusion\", \"pneumothorax\", \"cardiomegaly\"]\n",
    "    \n",
    "    # Initialize the results dictionary\n",
    "    results = {abnormality: 0 for abnormality in abnormalities}\n",
    "    \n",
    "    try:\n",
    "        # Parse the XML\n",
    "        root = ET.fromstring(xml_string)\n",
    "        \n",
    "        # Extract values\n",
    "        for abnormality in abnormalities:\n",
    "            element = root.find(f\".//{abnormality}\")\n",
    "            if element is not None:\n",
    "                results[abnormality] = int(element.text.strip())\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML: {e}\")\n",
    "        print(f\"XML string: {xml_string}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccb9e282-49fc-4bfb-953a-a525787712a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_radiology_reports(df):\n",
    "    \"\"\"\n",
    "    This function processes the radiology reports in the dataframe and extracts the abnormalities.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store the results\n",
    "    data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            report_text = row['Text']\n",
    "\n",
    "            # Here we assume `run_llama3` is your function that processes the report text and returns the XML\n",
    "            xml_output = classify_abnormalities(report_text)\n",
    "\n",
    "            # Extract abnormalities from the XML\n",
    "            abnormalities = extract_abnormalities_from_xml(xml_output)\n",
    "\n",
    "            # Combine the original text with the extracted abnormalities\n",
    "            data.append({**{'Text': report_text}, **abnormalities})\n",
    "        except:\n",
    "            print(f'WARNING! Issue with index: {index}')\n",
    "    \n",
    "    # Create a new dataframe from the results\n",
    "    new_df = pd.DataFrame(data)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dea374c-5b54-414a-8be5-6f9246f0dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df[:50].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6033d5ce-b728-4bd7-b79e-8e6461075b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing XML: syntax error: line 1, column 0\n",
      "XML string: .xml\n",
      "<?xml version=\"1.0\"?>\n",
      "<radiology_report>\n",
      "  <pulmonary_edema>0</pulmonary_edema>\n",
      "  <consolidation>0</consolidation>\n",
      "  <pleural_effusion>0</pleural_effusion>\n",
      "  <pneumothorax>0</pneumothorax>\n",
      "  <cardiomegaly>0</cardiomegaly>\n",
      "</radiology_report>\n"
     ]
    }
   ],
   "source": [
    "df_rad = process_radiology_reports(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91ed7dba-409d-48a2-a666-98222d2e4361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>pulmonary_edema</th>\n",
       "      <th>consolidation</th>\n",
       "      <th>pleural_effusion</th>\n",
       "      <th>pneumothorax</th>\n",
       "      <th>cardiomegaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXAM(S): Chest, 2 views, frontal and lateral\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nExam\\nXray Chest PA and Lateral\\n\\nDate\\nXXX...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nPA and Lateral Chest\\nXX...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nEXAM\\nPA and lateral che...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExam\\nPA and lateral che...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExam\\nPA and lateral che...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nExam\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\nEXAM\\nPA and LAT view CHEST XXXX, XXXX XXXX ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExam\\nPA and lateral che...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\nEXAM\\n2 VIEW CHEST: XXXX, XXXX at XXXX hours...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nEXAM\\nPA AND LATERAL VIE...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EXAM(S): Chest, 2 views, frontal and lateral\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\nEXAM\\nPA and LAT view CHEST XXXX, XXXX XXXX ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EXAM(S): Chest, 2 views, frontal and lateral\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExam\\nChest x-XXXX XXXX ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\\nExam\\nXray Chest PA and Lateral\\n\\nDate\\nXXX...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\\nExam\\nPA and lateral views of the Chest perf...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\\nExam\\nXray Chest PA and Lateral\\n\\nDate\\nXXX...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nChest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nHisto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nEXAM\\nPA and lateral vie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>\\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nHisto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>\\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\\nRADIOLOGY REPORT\\n\\nExam\\nRadiograph Chest P...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\\nExam\\nXray Chest PA and Lateral\\n\\nDate\\nXXX...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>\\nEXAM\\n2 VIEW CHEST: XXXX, XXXX at XXXX hours...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>\\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nExam\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>\\nEXAMINATION\\nPA and lateral chest radiograph...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>\\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nEXAM\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  pulmonary_edema  \\\n",
       "0   \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "1   EXAM(S): Chest, 2 views, frontal and lateral\\n...                0   \n",
       "2   \\nExam\\nXray Chest PA and Lateral\\n\\nDate\\nXXX...                0   \n",
       "3   \\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...                0   \n",
       "4   \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "5   \\nRADIOLOGY REPORT\\n\\nPA and Lateral Chest\\nXX...                0   \n",
       "6   \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "7   \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "8   \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "9   \\nRADIOLOGY REPORT\\n\\nEXAM\\nPA and lateral che...                0   \n",
       "10  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "11  \\nRADIOLOGY REPORT\\n\\nExam\\nPA and lateral che...                0   \n",
       "12  \\nRADIOLOGY REPORT\\n\\nExam\\nPA and lateral che...                0   \n",
       "13  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "14  \\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nExam\\...                0   \n",
       "15  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "16  \\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...                0   \n",
       "17  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "18  \\nEXAM\\nPA and LAT view CHEST XXXX, XXXX XXXX ...                0   \n",
       "19  \\nRADIOLOGY REPORT\\n\\nExam\\nPA and lateral che...                0   \n",
       "20  \\nEXAM\\n2 VIEW CHEST: XXXX, XXXX at XXXX hours...                0   \n",
       "21  \\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...                0   \n",
       "22  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "23  \\nRADIOLOGY REPORT\\n\\nEXAM\\nPA AND LATERAL VIE...                0   \n",
       "24  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "25  EXAM(S): Chest, 2 views, frontal and lateral\\n...                0   \n",
       "26  \\nEXAM\\nPA and LAT view CHEST XXXX, XXXX XXXX ...                0   \n",
       "27  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                1   \n",
       "28  EXAM(S): Chest, 2 views, frontal and lateral\\n...                0   \n",
       "29  \\nRADIOLOGY REPORT\\n\\nExam\\nChest x-XXXX XXXX ...                0   \n",
       "30  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "31  \\nExam\\nXray Chest PA and Lateral\\n\\nDate\\nXXX...                0   \n",
       "32  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "33  \\nExam\\nPA and lateral views of the Chest perf...                0   \n",
       "34  \\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...                0   \n",
       "35  \\nRADIOLOGY REPORT\\n\\nExamination\\nPA and late...                0   \n",
       "36  \\nExam\\nXray Chest PA and Lateral\\n\\nDate\\nXXX...                0   \n",
       "37  \\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nChest...                0   \n",
       "38  \\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nHisto...                0   \n",
       "39  \\nRADIOLOGY REPORT\\n\\nEXAM\\nPA and lateral vie...                0   \n",
       "40  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "41  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "42  \\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nHisto...                0   \n",
       "43  \\nChest PA-Lat XR\\n\\nImaging Study\\nXray Chest...                0   \n",
       "44  \\nRADIOLOGY REPORT\\n\\nExam\\nRadiograph Chest P...                0   \n",
       "45  \\nExam\\nXray Chest PA and Lateral\\n\\nDate\\nXXX...                0   \n",
       "46  \\nEXAM\\n2 VIEW CHEST: XXXX, XXXX at XXXX hours...                0   \n",
       "47  \\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nExam\\...                0   \n",
       "48  \\nEXAMINATION\\nPA and lateral chest radiograph...                0   \n",
       "49  \\nSIGNATURE\\nXXXX\\n\\nRADIOLOGY REPORT\\n\\nEXAM\\...                0   \n",
       "\n",
       "    consolidation  pleural_effusion  pneumothorax  cardiomegaly  \n",
       "0               0                 0             0             0  \n",
       "1               0                 0             0             1  \n",
       "2               0                 0             0             0  \n",
       "3               0                 0             0             0  \n",
       "4               0                 0             0             0  \n",
       "5               0                 0             0             0  \n",
       "6               0                 0             0             0  \n",
       "7               0                 0             0             0  \n",
       "8               0                 0             0             0  \n",
       "9               0                 0             0             0  \n",
       "10              0                 0             0             0  \n",
       "11              0                 0             0             0  \n",
       "12              0                 0             0             1  \n",
       "13              0                 0             0             0  \n",
       "14              0                 0             0             0  \n",
       "15              0                 0             0             0  \n",
       "16              0                 0             0             0  \n",
       "17              0                 0             0             0  \n",
       "18              0                 0             0             0  \n",
       "19              0                 0             0             0  \n",
       "20              0                 0             0             0  \n",
       "21              0                 0             0             0  \n",
       "22              0                 0             0             0  \n",
       "23              0                 0             0             0  \n",
       "24              1                 1             0             0  \n",
       "25              0                 0             0             0  \n",
       "26              0                 0             0             0  \n",
       "27              1                 0             0             1  \n",
       "28              1                 0             0             0  \n",
       "29              0                 0             0             0  \n",
       "30              0                 0             0             0  \n",
       "31              0                 0             0             0  \n",
       "32              0                 0             0             0  \n",
       "33              0                 0             0             0  \n",
       "34              0                 0             0             0  \n",
       "35              0                 0             0             0  \n",
       "36              1                 0             0             0  \n",
       "37              0                 0             0             0  \n",
       "38              0                 0             0             0  \n",
       "39              0                 0             0             0  \n",
       "40              0                 0             0             0  \n",
       "41              0                 0             0             0  \n",
       "42              0                 0             0             0  \n",
       "43              0                 0             0             0  \n",
       "44              0                 0             0             1  \n",
       "45              0                 0             0             0  \n",
       "46              0                 0             0             0  \n",
       "47              0                 0             0             0  \n",
       "48              0                 0             0             0  \n",
       "49              0                 0             0             1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b06415-cca2-42ac-bf40-85afe15cfaac",
   "metadata": {},
   "source": [
    "### Save the labels to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32253b4b-a515-45ea-9e6b-5ed151542a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rad.to_csv('../data/report_pseudo_labels_llama3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f18fcb4-8f04-4b5e-be12-d011981797a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRADIOLOGY REPORT\\n\\nExam\\nPA and lateral chest radiograph (2 views) (2 images) Date: XXXX, XXXX at XXXX hours Indication: Chest pain. Comparison: Chest radiograph from XXXX, XXXX. Findings: The cardiac silhouette is borderline enlarged. Otherwise, there is no focal opacity. Mediastinal contours are within normal limits. There is no large pleural effusion. No pneumothorax. Transcribed by - PSCB Transcription Date - XXXX\\n\\nIMPRESSION\\nBorderline enlargement of the cardiac silhouette without acute pulmonary disease. DICTATED BY : Dr. XXXX XXXX XXXX XXXX XXXX ELECTRONICALLY SIGNED XXXX. XXXX XXXX XXXX XXXX XXXX TRANSCRIBED XXXX 11 XXXX XXXX  RADRES XXXX\\n\\nSIGNATURE\\nXXXX\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['Text'][12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf11a83c-e1d3-4d88-aa2b-c4bc64d4812a",
   "metadata": {},
   "source": [
    "# Train a model on our pseudo labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaef8de-2eea-4de5-955e-b3497d810076",
   "metadata": {},
   "source": [
    "## Option 1: Fine Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da514fba-a70d-4f57-8205-46361b92b781",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b496530-b5e7-4594-8bd3-a02b2fbc807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.1-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from scikit-learn) (2.0.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-16.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/label-extractor/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading scikit_learn-1.5.0-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp311-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.2/390.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.1.0-cp311-cp311-macosx_11_0_arm64.whl (26.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp311-cp311-macosx_11_0_arm64.whl (410 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.3/410.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.4.1-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, xxhash, tqdm, threadpoolctl, sympy, scipy, safetensors, regex, pyarrow-hotfix, pyarrow, networkx, multidict, joblib, fsspec, frozenlist, filelock, dill, yarl, torch, scikit-learn, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 datasets-2.20.0 dill-0.3.8 filelock-3.15.4 frozenlist-1.4.1 fsspec-2024.5.0 huggingface-hub-0.23.4 joblib-1.4.2 mpmath-1.3.0 multidict-6.0.5 multiprocess-0.70.16 networkx-3.3 pyarrow-16.1.0 pyarrow-hotfix-0.6 regex-2024.5.15 safetensors-0.4.3 scikit-learn-1.5.0 scipy-1.13.1 sympy-1.12.1 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.3.1 tqdm-4.66.4 transformers-4.41.2 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn torch transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f01d8d-c23f-4dde-9113-e2eb3421e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Load your dataframe\n",
    "df = pd.read_csv('path_to_your_dataframe.csv')\n",
    "\n",
    "# Ensure the columns are in the correct format\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "df['pulmonary_edema'] = df['pulmonary_edema'].astype(int)\n",
    "df['consolidation'] = df['consolidation'].astype(int)\n",
    "df['pleural_effusion'] = df['pleural_effusion'].astype(int)\n",
    "df['pneumothorax'] = df['pneumothorax'].astype(int)\n",
    "df['cardiomegaly'] = df['cardiomegaly'].astype(int)\n",
    "\n",
    "# Split the dataframe into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert pandas dataframe to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Create a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a0440-b5a7-41fc-b94d-7f778fc38eb4",
   "metadata": {},
   "source": [
    "### Step 2: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4957902-4913-4a78-a741-328c6e211415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"RLHFlow/ArmoRM-Llama3-8B-v0.1\", use_fast=True)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['Text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "# Apply tokenization to the dataset\n",
    "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5767e-9a40-4fec-9721-ba6d8b2a18a2",
   "metadata": {},
   "source": [
    "### Step 3: Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93330b68-1c54-43ee-adef-e6a9d06dbada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"RLHFlow/ArmoRM-Llama3-8B-v0.1\",\n",
    "    num_labels=5,  # Number of labels (one for each abnormality)\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "# Define the columns to keep and set the format for PyTorch\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"Text\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a731e2-60fc-4365-8c51-c52aa6ff8ad9",
   "metadata": {},
   "source": [
    "### Step 4: Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76294ac9-da04-4c70-a147-2248769ca33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e187cf-e273-439f-be87-ef9a95f68593",
   "metadata": {},
   "source": [
    "### Step 5: Define the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b402bc-f739-45ed-93cd-08de1c67ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc55a4-591e-4843-9590-552e6027a774",
   "metadata": {},
   "source": [
    "### Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b6ef0-8971-4f83-ac87-43762e4f0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba0096-43b7-4f6a-b31c-77331253c6ff",
   "metadata": {},
   "source": [
    "## Option 2: Pre-trained model feature extractor\n",
    "\n",
    "This portion will largely follow chapter 2 of Natural Language Processing with Transformers by Tunstall, Werra, and Wolf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5f6b5-def2-4bda-a466-44b75f6e0163",
   "metadata": {},
   "source": [
    "To get code working and as a guide we can use the emotions dataset, which looks at classifying the emotion assocated with Twitter messages and is available from Hugging Face Hub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceac2c0-b16a-4f08-b3a5-babe960efa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789b963-3c8f-4a7c-9f55-90aa78595b23",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea42181-e69d-405e-a175-a12c2fcc13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'intfloat/e5-base-v2'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4816f-b15d-4d95-9a11-619a86dfc53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c71807-f39b-48b3-b335-f5381d41b776",
   "metadata": {},
   "source": [
    "### Extracting the last hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115688ee-85ea-4be1-bb3b-a2cddae2eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"some sample text\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594c052-208b-446a-bc62-889659dc18af",
   "metadata": {},
   "source": [
    "Note that the hidden state or embedding vector on the class token is being used here. This class token is the one typically used for classification tasks. We will start by using that here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca67ccd-f399-4b2e-97da-4e49c9968531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(batch):\n",
    "    inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52c6a61-0ab6-4106-9e91-8050739c11cf",
   "metadata": {},
   "source": [
    "### Create feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4b442-6a2e-4316-b9d3-94c430eba307",
   "metadata": {},
   "source": [
    "### Train model on the extracted features\n",
    "\n",
    "We could use a simple fully connected model where the final output has `sigmoid` activation function. Or we could use an ensemble model (e.g. xgboost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47511821-5263-4d19-9d0c-d98935b95a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
