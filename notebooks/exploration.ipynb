{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2ce46-786c-4413-b762-33b5f00df34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720ff7e-fc49-4537-9e32-ee29987576d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/ReportsDATASET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f41ac53-50d4-4c86-9a57-ef50b7e3104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68df1d-c6cb-49e3-89fd-2257e4fad602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de743e7f-b18e-44ab-8c4e-d6d9b5748969",
   "metadata": {},
   "source": [
    "## Run llama 3 locally\n",
    "\n",
    "- install `ollama`\n",
    "- run `ollama pull llama3` to pull down the llama 3 8B model \n",
    "- start the model running using `ollama run llama3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e51dcb6-8346-471d-9a5b-02abc26e2c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b121a070-9d32-4ac0-b957-261ceadfc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:11434/api/chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f8cf18-804a-4ecb-b3f5-669cf3158619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama3(prompt: str) -> str:\n",
    "    data = {\n",
    "        \"model\": \"llama3\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "    return response.json()['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e51af8-456a-4b77-a0cd-2a46a41bfb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llama3(\"who wrote the book the godfather?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4f297-b911-469a-bdbb-21a17147e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28517819-f505-40bf-9fb8-24cd3cf2a48d",
   "metadata": {},
   "source": [
    "### Extract labels using llama 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c933ec-5b2b-4d7f-afbe-86525fe1a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0856a2-778c-417e-a691-53d53764f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of abnormalities\n",
    "abnormalities = [\"pulmonary edema\", \"consolidation\", \"pleural effusion\", \"pneumothorax\", \"cardiomegaly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5675f4-2c43-47c2-bc28-f342cc340a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_abnormalities(report):\n",
    "    global abnormalities\n",
    "    \n",
    "    # Initialize results\n",
    "    results = {abnormality: 0 for abnormality in abnormalities}\n",
    "    \n",
    "    # Prepare the prompt for the GPT-4 model\n",
    "    prompt = f\"Read the following radiology report and identify the presence or absence of the following abnormalities: {', '.join(abnormalities)}.\\n\\nReport:\\n{report}\\n\\nOutput the results, formatted in xml, with each of the abnormalities with 0 for absence and 1 for presence. The output should be xml with no other text.\"\n",
    "    \n",
    "    # Get the classification results from llama 3\n",
    "    response = llama3(prompt)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e463097-c832-4a81-9e73-91da413ed978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_xml_string(xml_string):\n",
    "    \"\"\"\n",
    "    Clean the XML string to ensure it is well-formed.\n",
    "    \"\"\"\n",
    "    # Remove leading/trailing whitespace\n",
    "    xml_string = xml_string.strip()\n",
    "    \n",
    "    # Normalize the XML string\n",
    "    xml_string = xml_string.replace('-', '_').lower()\n",
    "    xml_string = xml_string.replace('pulmonary edema', 'pulmonary_edema').lower()\n",
    "    xml_string = xml_string.replace('pulmonaryedema', 'pulmonary_edema').lower()\n",
    "    xml_string = xml_string.replace('pleural effusion', 'pleural_effusion').lower()\n",
    "    xml_string = xml_string.replace('pleuraleffusion', 'pleural_effusion').lower()\n",
    "    \n",
    "    # Additional cleaning steps can be added here if needed\n",
    "    \n",
    "    return xml_string\n",
    "\n",
    "def extract_abnormalities_from_xml(xml_string):\n",
    "    \"\"\"\n",
    "    This function extracts abnormalities and their values from the given XML string.\n",
    "    \"\"\"\n",
    "    # Clean the XML string\n",
    "    xml_string = clean_xml_string(xml_string)\n",
    "    \n",
    "    # Define the list of abnormalities we're interested in\n",
    "    abnormalities = [\"pulmonary_edema\", \"consolidation\", \"pleural_effusion\", \"pneumothorax\", \"cardiomegaly\"]\n",
    "    \n",
    "    # Initialize the results dictionary\n",
    "    results = {abnormality: 0 for abnormality in abnormalities}\n",
    "    \n",
    "    try:\n",
    "        # Parse the XML\n",
    "        root = ET.fromstring(xml_string)\n",
    "        \n",
    "        # Extract values\n",
    "        for abnormality in abnormalities:\n",
    "            element = root.find(f\".//{abnormality}\")\n",
    "            if element is not None:\n",
    "                results[abnormality] = int(element.text.strip())\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML: {e}\")\n",
    "        print(f\"XML string: {xml_string}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb9e282-49fc-4bfb-953a-a525787712a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_radiology_reports(df):\n",
    "    \"\"\"\n",
    "    This function processes the radiology reports in the dataframe and extracts the abnormalities.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store the results\n",
    "    data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            report_text = row['Text']\n",
    "\n",
    "            # Here we assume `run_llama3` is your function that processes the report text and returns the XML\n",
    "            xml_output = classify_abnormalities(report_text)\n",
    "\n",
    "            # Extract abnormalities from the XML\n",
    "            abnormalities = extract_abnormalities_from_xml(xml_output)\n",
    "\n",
    "            # Combine the original text with the extracted abnormalities\n",
    "            data.append({**{'Text': report_text}, **abnormalities})\n",
    "        except:\n",
    "            print(f'WARNING! Issue with index: {index}')\n",
    "    \n",
    "    # Create a new dataframe from the results\n",
    "    new_df = pd.DataFrame(data)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea374c-5b54-414a-8be5-6f9246f0dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df[:40].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033d5ce-b728-4bd7-b79e-8e6461075b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rad = process_radiology_reports(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed7dba-409d-48a2-a666-98222d2e4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18fcb4-8f04-4b5e-be12-d011981797a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['Text'][12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf11a83c-e1d3-4d88-aa2b-c4bc64d4812a",
   "metadata": {},
   "source": [
    "## Train a model on our pseudo labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da514fba-a70d-4f57-8205-46361b92b781",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f01d8d-c23f-4dde-9113-e2eb3421e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Load your dataframe\n",
    "df = pd.read_csv('path_to_your_dataframe.csv')\n",
    "\n",
    "# Ensure the columns are in the correct format\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "df['pulmonary_edema'] = df['pulmonary_edema'].astype(int)\n",
    "df['consolidation'] = df['consolidation'].astype(int)\n",
    "df['pleural_effusion'] = df['pleural_effusion'].astype(int)\n",
    "df['pneumothorax'] = df['pneumothorax'].astype(int)\n",
    "df['cardiomegaly'] = df['cardiomegaly'].astype(int)\n",
    "\n",
    "# Split the dataframe into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert pandas dataframe to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Create a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a0440-b5a7-41fc-b94d-7f778fc38eb4",
   "metadata": {},
   "source": [
    "### Step 2: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4957902-4913-4a78-a741-328c6e211415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"RLHFlow/ArmoRM-Llama3-8B-v0.1\", use_fast=True)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['Text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "# Apply tokenization to the dataset\n",
    "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5767e-9a40-4fec-9721-ba6d8b2a18a2",
   "metadata": {},
   "source": [
    "### Step 3: Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93330b68-1c54-43ee-adef-e6a9d06dbada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"RLHFlow/ArmoRM-Llama3-8B-v0.1\",\n",
    "    num_labels=5,  # Number of labels (one for each abnormality)\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "# Define the columns to keep and set the format for PyTorch\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"Text\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a731e2-60fc-4365-8c51-c52aa6ff8ad9",
   "metadata": {},
   "source": [
    "### Step 4: Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76294ac9-da04-4c70-a147-2248769ca33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e187cf-e273-439f-be87-ef9a95f68593",
   "metadata": {},
   "source": [
    "### Step 5: Define the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b402bc-f739-45ed-93cd-08de1c67ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc55a4-591e-4843-9590-552e6027a774",
   "metadata": {},
   "source": [
    "### Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b6ef0-8971-4f83-ac87-43762e4f0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d38dc7-3db0-462c-b4f8-5d8bd1fe8da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
